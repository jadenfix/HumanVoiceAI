# configs/rl_policy_config.yaml
# RL Policy Configuration

# Network architecture
network:
  hidden_dims: [128, 64]
  dropout: 0.2

# Training parameters
training:
  lr: 1e-4
  gamma: 0.99
  batch_size: 64
  buffer_size: 10000
  target_update: 10

# Exploration
exploration:
  epsilon_start: 1.0
  epsilon_end: 0.01
  epsilon_decay: 0.995

# Rewards
rewards:
  correct_emotion: 1.0
  incorrect_emotion: -0.5
  neutral_response: 0.1

# Action space
actions:
  - name: "neutral"
    description: "Respond in a neutral tone"
  - name: "happy"
    description: "Respond in a happy/positive tone"
  - name: "sad"
    description: "Respond in a sad/empathetic tone"
  - name: "angry"
    description: "Respond in a firm/assertive tone"
  - name: "surprised"
    description: "Respond with surprise/enthusiasm"
  - name: "calm"
    description: "Respond in a calming/reassuring tone"